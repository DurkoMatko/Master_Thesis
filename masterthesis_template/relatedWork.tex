Thesis itself combines many fields and areas. Its main topics are Git mining, Twitter mining, sentiment analysis and text similarity.\\
\\
Nice example to Git mining was done by Russel and Mathew \cite{russell2013mining}. They discovered 9 interesting perils and according to their paper, most projects are inactive and have low count of commits. Two thirds of repositories are personal and large portion of these are not software development projects. Also, usage of pull-request is not very often and many projects do not conduct all their software to the Git. Similar study to my own was executed by Tsay et al. \cite{tsay2012social}. They developed two measures of project success - Developer Attention and Work
Contribution. They found out that projects with highly socially connected developers are not necessarily the most
active or popular projects and projects with a high level of developer multitasking surprisingly tend to receive less
Developer Attention, but greater Work Contribution. Little evidence that usage of specific social media features in GitHub directly correlates with software project success was found.  Takhteyev et al. \cite{takhteyev2010investigating} explored developers' geographic locations by examining self-reported information available within GitHub profiles. Research has also been done regarding availability and retrieval improvement of Git data (\cite{wagstrom2013network} and \cite{gousios2012ghtorrent}). Sentiment analysis of Git commits was described in Guzman at al \cite{guzman2014sentiment}.\\
\\
Last mentioned paper brings me to another part of my thesis, which was sentiment analysis. Although I am utilizing Git features, my sentiment analysis is actually executed on the Twitter data. Like I mention in Section \ref{ssec:GettingData}, Twitter is a default choice for social media sentiment analysis. That means lot of work has already been done in this area (e.g \cite{agarwal2011sentiment}, \cite{kouloumpis2011twitter}, \cite{pak2010twitter}, \cite{saif2012semantic} or Nakov et al. yearly paper update \cite{nakov2016semeval},\cite{rosenthal2017semeval}).\\
\\
Much less saturated is the topic of linking social media and  git repositories. I have not found any paper tackling this problem. The closest topic to this is probably duplicate bug detection as it also requires extracting and understanding of bug descriptions. Algorithm by Anvik at al. \cite{anvik2005coping} assigns incoming bug reports to correct developers with 64\% precision based on the textual features of the report. Weiss et al. \cite{weiss2007long} and Giger at al. \cite{giger2010predicting} predict time required to fix a bug based on their attributes. Bug analysis most similar to my work was done by Runeson at al. \cite{runeson2007detection}. They implement and test a technique of detecting bug duplicates using NLP. The evaluation shows that about 2/3 of
the duplicates can possibly be found. Similar task was tackled by Jalbert and Weimer \cite{jalbert2008automated} who introduced an algorithm which flags duplicate bug reports on their arrival. They claim to reduce the development costs by 8\% while still allowing at least one reported issue per bug to reach developers.\\
\\
Thesis has 2 separate parts, each tackling its own unique task. Both parts utilize simple Term Frequency Inverse Document Frequency (TF-IDF) to extract word relevance from text. It has been discussed and used for this task in many papers over the years (more widely known are e.g. \cite{ramos2003using}, \cite{lan2005comprehensive} or \cite{gamon2005pulse}).