One of the main building blocks of any correctly and accurately functioning ML projects is a training phase. It can actually be seen as a base for the whole project. One can have the best fine-tuned optimized classifier, but if the training data he used do not fit the domain where the classifier is intended to be used, results of the classifier can be (surprisingly) bad. It's the same as house and its base. If the base is not done correctly, however cool architectural solution have other storeys used, house is still going to fall in the next big storm.

That's why choosing a sufficient and fitting dataset to train my classifiers was a very important task. The datasets I've considered were:
\begin{itemize}
  \item \textbf{Dataset140}\footnote{http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip} - it is currently the biggest dataset with tweets labeled by their sentiment. What is interesting and makes the dataset special is that opposed to other datasets being manually annotated by humans, this one was created by a program. It contains 1.6 million tweets with their polarity score (0 = negative, 2 = neutral, 4 = positive), tweet id, date of tweet publication, author of the tweet and the text of the tweet. More about how this dataset was created can be found in Go et al. paper \cite{go2009twitter}
  \item \textbf{Movie review data}\footnote{http://www.cs.cornell.edu/people/pabo/movie-review-data/} - Thousand positive and thousand negative labeled movie reviews. This dataset was introduced in Pang/Lee ACL 2004 \cite{pang2004sentimental}
  \item \textbf{Hu-Liu lexicon}\footnote{https://github.com/woodrad/Twitter-Sentiment-Mining/tree/master/Hu\%20and\%20Liu\%20Sentiment\%20Lexicon} - plain list of 6800 common English words labeled as positive and negative
  \item \textbf{Warriner et al lexicon}\footnote{http://crr.ugent.be/archives/1003} - This list of words was collected with Amazon Mechanical Turk. Three components of emotions are traditionally distinguished: valence (the pleasantness of a stimulus), arousal (the intensity of emotion provoked by a stimulus), and dominance (the degree of control exerted by a stimulus) \cite{warriner2013norms}. Warriner and Kuperman extended ANEW norms collected by Bradley and Lang from 1034 words to 13,915 words (lemmas).
  \item \textbf{Stack overflow dataset}\footnote{https://sentiment-se.github.io/replication.zip} - Later into the thesis I've decided to test dataset of 1500 manually labeled Stack overflow sentences created by Bin Lin et al. in their late paper on negative results in SA called "How far can we go"
    \item \textbf{My own cryptocurrency tweets dataset} - As already said before, performance of the classifier depends on how close the training data are to the real use-case data. That's why I considered and even started to create my own dataset targeting specifically only cryptocurrency tweets.
\end{itemize}